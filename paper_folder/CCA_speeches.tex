\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2020}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}

\title{Formatting Instructions For NeurIPS 2020}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\title{Understanding Presidential Speeches\\ and Executive Orders with Natural Language Processing\\
	\large Computational Content Analysis}

\author{Lily Grier \\
	\texttt{lilygrier@uchicago.edu}  \\
	The University of Chicago
	\AND
	Linh Dinh\\
	\texttt{ldinh@uchicago.edu} \\
    The University of Chicago\\
	\AND
	Roberto Barroso-Luque\\
	\texttt{barrosoluquer@uchicago.edu} \\
	The University of Chicago\\}

\begin{document}
\maketitle

\begin{abstract}{
BLABLABLA }
\end{abstract}

\newpage
\section{Introduction}
BLABLABLA

\section{Methodology}{

\subsection{Datasets}{BLABLABLA}


\subsection{Data Pre-processing}{BLABLABLA}


\subsection{Other methods}{BLABLABLA}


\subsection{Even more methods}{BLABLABLA}


\section{Results}{
\subsection{Some subsection}{BLABLABLA}

\subsection{Another subsection}{BLABLABLA }

\subsection{Conclusion}{BLABLABLA} 
}

\begin{figure}
\end{figure}


\begin{table}
  \caption{Number of principal component vectors and ratio of variance explained.}
  \centering
  \begin{tabular}{lll}
    \toprule
    \midrule
    Dataset     & PCA Vectors Used       & Variance Explained \\
    \midrule
    \midrule
    Heart Disease(continuous only) & 1 & .25     \\
    \midrule
    Heart Disease & 2 & .41     \\
    \midrule
    Divorce     & 1 & .31    \\
    \midrule
    NBA Rookies     & 2   & .55 \\
    \midrule
    Mushrooms     & 1   & .34 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}
	\caption{ Original features with highest correlation to chosen principal component vectors.}
	\centering
	\begin{tabular}{lll}
    \toprule
	\midrule
	Dataset     & Original feature (label)     & Correlation to PC vector(R2) \\
	\midrule
	\midrule
	Heart Disease(continuous only) & Thalach (max heart rate) & .89     \\
	\midrule
	Heart Disease & Age & .69     \\
	\midrule
	Divorce     & Atr7  & .45    \\
	\midrule
	NBA Rookies     & Offensive Rebounds   & .80 \\
	\midrule
	Mushrooms     & Stalk Shape-enlarging and shape-tapering   & .58 \\
	\bottomrule
	\end{tabular}
\end{table}

\begin{table}
	\caption{Original features with highest correlation to chosen “interpretable direction” vectors }
	\centering
	\begin{tabular}{lll}
		\toprule
		\midrule
		Dataset     & Original feature (label)     & Correlation to ID vectors(R2) \\
		\midrule
		\midrule
		Heart Disease(continuous only) & Thalach (max heart rate) & .79     \\
		\midrule
		Heart Disease & Oldpeak & .58     \\
		\midrule
		NBA Rookies     & Offensive Rebounds   & .68 \\
		\midrule
		Mushrooms  & Odor-musty, ring-type-none, ring-number-none   & .88 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}
	\caption{ Prediction accuracy using PCs, IDs, and original feature space}
	\centering
	
	\begin{tabular}{llll}
		\toprule
		\midrule	
		Dataset     & Full features space (Least Squares) & PCA Least Squares & ID Least Squares \\
		\midrule
		\midrule
		Heart Disease(continuous only) & .72 & .70 & .40    \\
		\midrule
		Heart Disease*  & .59 & .77 & .70    \\
		\midrule
		Divorce     & 1.00 & .50 & NA  \\
		\midrule
		NBA Rookies   & .67 & .56 & .41    \\
		\midrule
		Mushrooms     & .48 & .47 & .47    \\
		\bottomrule
	\end{tabular}
Note: For all classification tasks the feature matrix was broken into 80\% training set and 20\% testing set. 
Accuracy shown in the table is based on the training set.
*These errors are not what we expected. See findings section.
\end{table}




\section{References}\label{sec_ref}

[1] Chipman H. \& Gu H. (2006): Interpretable dimension reduction. 
{\it Journal of Applied Statistics}

[2] Ding J. , Condon A. \& P.Shah S. (2018). Interpretable dimensionality reduction \\ of single cell transcriptome data with deep generative models. 
{\it Nature Communications}

[3]Hosseini B. \& Hammer B (2019): Interpretable Discriminative Dimensionality Reduction \\ and Feature Selection on the Manifold.
{\it BiorXiv}


\end{document}
